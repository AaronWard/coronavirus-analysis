{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import os.path\n",
    "from datetime import datetime, date, time \n",
    "from dateutil.parser import parse\n",
    "from time import strftime\n",
    "import pyarrow\n",
    "import json\n",
    "import git\n",
    "\n",
    "REPO = 'https://github.com/CSSEGISandData/COVID-19.git'\n",
    "TMP_FOLDER = '/tmp/corona/'\n",
    "TMP_GIT = os.path.join(TMP_FOLDER, 'COVID-19')\n",
    "DATA = os.path.join(TMP_GIT, 'csse_covid_19_data/csse_covid_19_daily_reports/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting out of date repo...\n",
      "Cloning Data Repo...\n",
      "Cleaning sheets...\n"
     ]
    }
   ],
   "source": [
    "def clean_sheet_names(new_ranges):\n",
    "    '''\n",
    "    Get rid of the duplicate sheets, only take the sheets from the \n",
    "    latest point in the day\n",
    "    '''\n",
    "    indices = []\n",
    "    \n",
    "    # Remove all sheets that dont have a numeric header\n",
    "    numeric_sheets = [x for x in new_ranges if re.search(r'\\d', x)]\n",
    "    \n",
    "    return numeric_sheets\n",
    "\n",
    "def clone_repo(TMP_FOLDER, REPO):\n",
    "    print('Cloning Data Repo...')\n",
    "    git.Git(TMP_FOLDER).clone(REPO)\n",
    "\n",
    "# Create Tmp Folder\n",
    "if not os.path.isdir(TMP_FOLDER):\n",
    "    print('Creating folder...')\n",
    "    print('...', TMP_FOLDER)\n",
    "    os.mkdir(TMP_FOLDER)\n",
    "\n",
    "#Check if repo exists\n",
    "if not os.path.isdir(TMP_GIT):\n",
    "    clone_repo(TMP_FOLDER, REPO)\n",
    "else:\n",
    "    #get up to date repo\n",
    "    print('Deleting out of date repo...')\n",
    "    os.system('rm -rf ' + str(TMP_GIT))\n",
    "    clone_repo(TMP_FOLDER, REPO)\n",
    "    \n",
    "sheets = os.listdir(DATA)\n",
    "\n",
    "# Clean the result to the sheet tabs we want\n",
    "print('Cleaning sheets...')\n",
    "cleaned_sheets = clean_sheet_names(sheets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "For assigning date by the time sheet name\n",
    "'''\n",
    "\n",
    "def clean_last_updates(last_update):\n",
    "    date = parse(str(last_update).split(' ')[0]).strftime(\"%Y-%m-%d\")\n",
    "    time = parse(str(last_update).split(' ')[1]).strftime('%H:%M:%S')\n",
    "    parsed_date = str(date) + ' ' + str(time)\n",
    "\n",
    "    return parsed_date\n",
    "\n",
    "def get_date(last_update):\n",
    "    return parse(str(last_update).split(' ')[0]).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def drop_duplicates(df_raw):\n",
    "    '''\n",
    "    Take the max date value for each province for a given date\n",
    "    '''\n",
    "    days_list = []\n",
    "    \n",
    "    for datetime in df_raw.date.unique():\n",
    "        tmp_df = df_raw[df_raw.date == datetime]\n",
    "        tmp_df = tmp_df.sort_values(['Last Update']).drop_duplicates('Province/State', keep='last')\n",
    "        days_list.append(tmp_df)\n",
    "\n",
    "    return days_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... 01-22-2020.csv\n",
      "... 01-23-2020.csv\n",
      "... 01-24-2020.csv\n",
      "... 01-25-2020.csv\n",
      "... 01-26-2020.csv\n",
      "... 01-27-2020.csv\n",
      "... 01-28-2020.csv\n",
      "... 01-29-2020.csv\n",
      "... 01-30-2020.csv\n",
      "... 01-31-2020.csv\n",
      "... 02-01-2020.csv\n",
      "... 02-02-2020.csv\n",
      "... 02-03-2020.csv\n",
      "... 02-04-2020.csv\n",
      "... 02-05-2020.csv\n",
      "... 02-06-2020.csv\n",
      "... 02-07-2020.csv\n",
      "... 02-08-2020.csv\n",
      "... 02-09-2020.csv\n",
      "... 02-10-2020.csv\n",
      "... 02-11-2020.csv\n",
      "... 02-12-2020.csv\n",
      "... 02-13-2020.csv\n",
      "... 02-14-2020.csv\n",
      "... 02-15-2020.csv\n",
      "... 02-16-2020.csv\n",
      "... 02-17-2020.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "keep_cols = ['Confirmed', 'Country/Region', 'Deaths', 'Last Update', 'Province/State', 'Recovered']\n",
    "numeric_cols = ['Confirmed', 'Deaths', 'Recovered']\n",
    "\n",
    "def get_data(cleaned_sheets):\n",
    "    all_csv = []\n",
    "    # Import all CSV's\n",
    "    for file in sorted(sheets):\n",
    "        if 'csv' in file:\n",
    "            print('...', file)\n",
    "            tmp_df = pd.read_csv(os.path.join(DATA, file), index_col=None, header=0, parse_dates=['Last Update'])\n",
    "            tmp_df = tmp_df[keep_cols]\n",
    "            tmp_df[numeric_cols] = tmp_df[numeric_cols].fillna(0)\n",
    "            tmp_df[numeric_cols] = tmp_df[numeric_cols].astype(int)\n",
    "            tmp_df['Province/State'].fillna(tmp_df['Country/Region'], inplace=True)\n",
    "\n",
    "            tmp_df['Last Update'] = tmp_df['Last Update'].apply(clean_last_updates)\n",
    "            tmp_df['date'] = tmp_df['Last Update'].apply(get_date)\n",
    "\n",
    "            all_csv.append(tmp_df)\n",
    "\n",
    "    df_raw = pd.concat(all_csv, axis=0, ignore_index=True, sort=True)\n",
    "    df_raw = df_raw.sort_values(by=['Last Update'])\n",
    "\n",
    "    #Get the last entry per region by date\n",
    "    frames = drop_duplicates(df_raw)\n",
    "    tmp = pd.concat(frames, axis=0, ignore_index=True, sort=True)\n",
    "    \n",
    "    return tmp\n",
    "\n",
    "\n",
    "df = get_data(cleaned_sheets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning dataframes...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now that we have all the data we now need to clean it \n",
    "# - Fill null values\n",
    "# - remore suspected values\n",
    "# - change column names\n",
    "def clean_data(tmp_df):\n",
    "    if 'Demised' in tmp_df.columns:\n",
    "        tmp_df.rename(columns={'Demised':'Deaths'}, inplace=True)\n",
    "\n",
    "    if 'Country/Region' in tmp_df.columns:\n",
    "        tmp_df.rename(columns={'Country/Region':'country'}, inplace=True)\n",
    "    \n",
    "    if 'Province/State' in tmp_df.columns:\n",
    "        tmp_df.rename(columns={'Province/State':'province'}, inplace=True)\n",
    "        \n",
    "    if 'Last Update' in tmp_df.columns:\n",
    "        tmp_df.rename(columns={'Last Update':'datetime'}, inplace=True)\n",
    "        \n",
    "    if 'Suspected' in tmp_df.columns:\n",
    "        tmp_df = tmp_df.drop(columns='Suspected')\n",
    "\n",
    "    for col in tmp_df.columns:\n",
    "        tmp_df[col] = tmp_df[col].fillna(0)\n",
    "    \n",
    "    #Lower case all col names\n",
    "    tmp_df.columns = map(str.lower, tmp_df.columns) \n",
    "    return tmp_df\n",
    "\n",
    "print('Cleaning dataframes...')\n",
    "df  = clean_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting by datetime...\n"
     ]
    }
   ],
   "source": [
    "# sheets need to be sorted by date value\n",
    "print('Sorting by datetime...')\n",
    "current_date = str(datetime.date(datetime.now()))\n",
    "\n",
    "if df.date.max() == current_date:\n",
    "    df = df[df.date != df.date.max()]\n",
    "else:\n",
    "    df = df[df.date != current_date]\n",
    "\n",
    "df = df.sort_values('datetime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dataframe for new cases...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Get the difference of the sum totals for each\n",
    "date and plot them on a trendline graph\n",
    "'''\n",
    "def get_new_cases(tmp, col):\n",
    "    diff_list = []\n",
    "    tmp_df_list = []\n",
    "    df = tmp.copy()\n",
    "\n",
    "    for i, day in enumerate(df.date.unique()):    \n",
    "        tmp_df = df[df.date == day]\n",
    "        tmp_df_list.append(tmp_df[col].sum())\n",
    "        \n",
    "        if i == 0:\n",
    "            diff_list.append(tmp_df[col].sum())\n",
    "        else:\n",
    "            diff_list.append(tmp_df[col].sum() - tmp_df_list[i-1])\n",
    "        \n",
    "    return diff_list\n",
    "\n",
    "def get_moving_average(tmp, col):\n",
    "    df = tmp.copy()\n",
    "    return df[col].rolling(window=2).mean()\n",
    "\n",
    "def get_exp_moving_average(tmp, col):\n",
    "    df = tmp.copy()\n",
    "    return df[col].ewm(span=2, adjust=True).mean()\n",
    "\n",
    "\n",
    "print('Calculating dataframe for new cases...')\n",
    "daily_cases_df = pd.DataFrame([])\n",
    "daily_cases_df['new_confirmed_cases'] = get_new_cases(df, 'confirmed')\n",
    "daily_cases_df['new_deaths'] = get_new_cases(df, 'deaths')\n",
    "daily_cases_df['new_recoveries'] = get_new_cases(df, 'recovered')\n",
    "daily_cases_df['date'] = df.date.unique()\n",
    "\n",
    "\n",
    "daily_cases_df['confirmed_MA'] = get_moving_average(daily_cases_df, 'new_confirmed_cases')\n",
    "daily_cases_df['deaths_moving_MA'] = get_moving_average(daily_cases_df, 'new_deaths')\n",
    "daily_cases_df['recovered_moving_MA'] = get_moving_average(daily_cases_df, 'new_recoveries')\n",
    "\n",
    "daily_cases_df['confirmed_exp_MA'] = get_exp_moving_average(daily_cases_df, 'new_confirmed_cases')\n",
    "daily_cases_df['deaths_moving_exp_MA'] = get_exp_moving_average(daily_cases_df, 'new_deaths')\n",
    "daily_cases_df['recovered_moving_exp_MA'] = get_exp_moving_average(daily_cases_df, 'new_recoveries')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_confirmed_cases</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_recoveries</th>\n",
       "      <th>date</th>\n",
       "      <th>confirmed_MA</th>\n",
       "      <th>deaths_moving_MA</th>\n",
       "      <th>recovered_moving_MA</th>\n",
       "      <th>confirmed_exp_MA</th>\n",
       "      <th>deaths_moving_exp_MA</th>\n",
       "      <th>recovered_moving_exp_MA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>555</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>326.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>212.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>288</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>193.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>264.692308</td>\n",
       "      <td>7.076923</td>\n",
       "      <td>6.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>497</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>392.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>421.500000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>4.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>680</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>588.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>594.545455</td>\n",
       "      <td>13.702479</td>\n",
       "      <td>10.099174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>809</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>744.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>737.711538</td>\n",
       "      <td>21.912088</td>\n",
       "      <td>9.365385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2651</td>\n",
       "      <td>49</td>\n",
       "      <td>46</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>27.5</td>\n",
       "      <td>2013.820677</td>\n",
       "      <td>39.978957</td>\n",
       "      <td>33.799634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>587</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>1619.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1062.461890</td>\n",
       "      <td>14.655793</td>\n",
       "      <td>23.931707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2070</td>\n",
       "      <td>38</td>\n",
       "      <td>17</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>1328.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1734.188091</td>\n",
       "      <td>30.219388</td>\n",
       "      <td>19.310334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1690</td>\n",
       "      <td>42</td>\n",
       "      <td>79</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1704.728865</td>\n",
       "      <td>38.073262</td>\n",
       "      <td>59.104119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2027</td>\n",
       "      <td>46</td>\n",
       "      <td>55</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>1858.5</td>\n",
       "      <td>44.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1919.577501</td>\n",
       "      <td>43.357784</td>\n",
       "      <td>56.368024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4733</td>\n",
       "      <td>103</td>\n",
       "      <td>186</td>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>3380.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>120.5</td>\n",
       "      <td>3795.196030</td>\n",
       "      <td>83.119336</td>\n",
       "      <td>142.789504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3034</td>\n",
       "      <td>63</td>\n",
       "      <td>152</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>3883.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>3287.731692</td>\n",
       "      <td>69.706437</td>\n",
       "      <td>148.929839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4102</td>\n",
       "      <td>66</td>\n",
       "      <td>234</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>3568.0</td>\n",
       "      <td>64.5</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3830.577344</td>\n",
       "      <td>67.235478</td>\n",
       "      <td>205.643291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3636</td>\n",
       "      <td>72</td>\n",
       "      <td>265</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>3869.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>249.5</td>\n",
       "      <td>3700.859106</td>\n",
       "      <td>70.411826</td>\n",
       "      <td>245.214433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3169</td>\n",
       "      <td>70</td>\n",
       "      <td>362</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>3402.5</td>\n",
       "      <td>71.0</td>\n",
       "      <td>313.5</td>\n",
       "      <td>3346.286360</td>\n",
       "      <td>70.137275</td>\n",
       "      <td>323.071480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3638</td>\n",
       "      <td>86</td>\n",
       "      <td>522</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>3403.5</td>\n",
       "      <td>78.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>3540.762122</td>\n",
       "      <td>80.712425</td>\n",
       "      <td>455.690494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2651</td>\n",
       "      <td>86</td>\n",
       "      <td>610</td>\n",
       "      <td>2020-02-08</td>\n",
       "      <td>3144.5</td>\n",
       "      <td>86.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>2947.587372</td>\n",
       "      <td>84.237475</td>\n",
       "      <td>558.563498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3082</td>\n",
       "      <td>100</td>\n",
       "      <td>617</td>\n",
       "      <td>2020-02-09</td>\n",
       "      <td>2866.5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>613.5</td>\n",
       "      <td>3037.195791</td>\n",
       "      <td>94.745825</td>\n",
       "      <td>597.521166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2490</td>\n",
       "      <td>107</td>\n",
       "      <td>675</td>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>2786.0</td>\n",
       "      <td>103.5</td>\n",
       "      <td>646.0</td>\n",
       "      <td>2672.398597</td>\n",
       "      <td>102.915275</td>\n",
       "      <td>649.173722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2014</td>\n",
       "      <td>100</td>\n",
       "      <td>770</td>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>2252.0</td>\n",
       "      <td>103.5</td>\n",
       "      <td>722.5</td>\n",
       "      <td>2233.466199</td>\n",
       "      <td>100.971758</td>\n",
       "      <td>729.724574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>576</td>\n",
       "      <td>6</td>\n",
       "      <td>454</td>\n",
       "      <td>2020-02-12</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>1128.488733</td>\n",
       "      <td>37.657253</td>\n",
       "      <td>545.908191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15001</td>\n",
       "      <td>252</td>\n",
       "      <td>1147</td>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>7788.5</td>\n",
       "      <td>129.0</td>\n",
       "      <td>800.5</td>\n",
       "      <td>10376.829578</td>\n",
       "      <td>180.552418</td>\n",
       "      <td>946.636064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6494</td>\n",
       "      <td>150</td>\n",
       "      <td>1680</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>10747.5</td>\n",
       "      <td>201.0</td>\n",
       "      <td>1413.5</td>\n",
       "      <td>7788.276526</td>\n",
       "      <td>160.184139</td>\n",
       "      <td>1435.545355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2264</td>\n",
       "      <td>144</td>\n",
       "      <td>1399</td>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>4379.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1539.5</td>\n",
       "      <td>4105.425509</td>\n",
       "      <td>149.394713</td>\n",
       "      <td>1411.181785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2181</td>\n",
       "      <td>104</td>\n",
       "      <td>1428</td>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>2222.5</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1413.5</td>\n",
       "      <td>2822.475170</td>\n",
       "      <td>119.131571</td>\n",
       "      <td>1422.393928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2080</td>\n",
       "      <td>98</td>\n",
       "      <td>1731</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>2130.5</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1579.5</td>\n",
       "      <td>2327.491723</td>\n",
       "      <td>105.043857</td>\n",
       "      <td>1628.131309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    new_confirmed_cases  new_deaths  new_recoveries        date  confirmed_MA  \\\n",
       "0                   555          17              28  2020-01-22           NaN   \n",
       "1                    98           1               2  2020-01-23         326.5   \n",
       "2                   288           8               6  2020-01-24         193.0   \n",
       "3                   497          16               3  2020-01-25         392.5   \n",
       "4                   680          14              13  2020-01-26         588.5   \n",
       "5                   809          26               9  2020-01-27         744.5   \n",
       "6                  2651          49              46  2020-01-28        1730.0   \n",
       "7                   587           2              19  2020-01-29        1619.0   \n",
       "8                  2070          38              17  2020-01-30        1328.5   \n",
       "9                  1690          42              79  2020-01-31        1880.0   \n",
       "10                 2027          46              55  2020-02-01        1858.5   \n",
       "11                 4733         103             186  2020-02-02        3380.0   \n",
       "12                 3034          63             152  2020-02-03        3883.5   \n",
       "13                 4102          66             234  2020-02-04        3568.0   \n",
       "14                 3636          72             265  2020-02-05        3869.0   \n",
       "15                 3169          70             362  2020-02-06        3402.5   \n",
       "16                 3638          86             522  2020-02-07        3403.5   \n",
       "17                 2651          86             610  2020-02-08        3144.5   \n",
       "18                 3082         100             617  2020-02-09        2866.5   \n",
       "19                 2490         107             675  2020-02-10        2786.0   \n",
       "20                 2014         100             770  2020-02-11        2252.0   \n",
       "21                  576           6             454  2020-02-12        1295.0   \n",
       "22                15001         252            1147  2020-02-13        7788.5   \n",
       "23                 6494         150            1680  2020-02-14       10747.5   \n",
       "24                 2264         144            1399  2020-02-15        4379.0   \n",
       "25                 2181         104            1428  2020-02-16        2222.5   \n",
       "26                 2080          98            1731  2020-02-17        2130.5   \n",
       "\n",
       "    deaths_moving_MA  recovered_moving_MA  confirmed_exp_MA  \\\n",
       "0                NaN                  NaN        555.000000   \n",
       "1                9.0                 15.0        212.250000   \n",
       "2                4.5                  4.0        264.692308   \n",
       "3               12.0                  4.5        421.500000   \n",
       "4               15.0                  8.0        594.545455   \n",
       "5               20.0                 11.0        737.711538   \n",
       "6               37.5                 27.5       2013.820677   \n",
       "7               25.5                 32.5       1062.461890   \n",
       "8               20.0                 18.0       1734.188091   \n",
       "9               40.0                 48.0       1704.728865   \n",
       "10              44.0                 67.0       1919.577501   \n",
       "11              74.5                120.5       3795.196030   \n",
       "12              83.0                169.0       3287.731692   \n",
       "13              64.5                193.0       3830.577344   \n",
       "14              69.0                249.5       3700.859106   \n",
       "15              71.0                313.5       3346.286360   \n",
       "16              78.0                442.0       3540.762122   \n",
       "17              86.0                566.0       2947.587372   \n",
       "18              93.0                613.5       3037.195791   \n",
       "19             103.5                646.0       2672.398597   \n",
       "20             103.5                722.5       2233.466199   \n",
       "21              53.0                612.0       1128.488733   \n",
       "22             129.0                800.5      10376.829578   \n",
       "23             201.0               1413.5       7788.276526   \n",
       "24             147.0               1539.5       4105.425509   \n",
       "25             124.0               1413.5       2822.475170   \n",
       "26             101.0               1579.5       2327.491723   \n",
       "\n",
       "    deaths_moving_exp_MA  recovered_moving_exp_MA  \n",
       "0              17.000000                28.000000  \n",
       "1               5.000000                 8.500000  \n",
       "2               7.076923                 6.769231  \n",
       "3              13.100000                 4.225000  \n",
       "4              13.702479                10.099174  \n",
       "5              21.912088                 9.365385  \n",
       "6              39.978957                33.799634  \n",
       "7              14.655793                23.931707  \n",
       "8              30.219388                19.310334  \n",
       "9              38.073262                59.104119  \n",
       "10             43.357784                56.368024  \n",
       "11             83.119336               142.789504  \n",
       "12             69.706437               148.929839  \n",
       "13             67.235478               205.643291  \n",
       "14             70.411826               245.214433  \n",
       "15             70.137275               323.071480  \n",
       "16             80.712425               455.690494  \n",
       "17             84.237475               558.563498  \n",
       "18             94.745825               597.521166  \n",
       "19            102.915275               649.173722  \n",
       "20            100.971758               729.724574  \n",
       "21             37.657253               545.908191  \n",
       "22            180.552418               946.636064  \n",
       "23            160.184139              1435.545355  \n",
       "24            149.394713              1411.181785  \n",
       "25            119.131571              1422.393928  \n",
       "26            105.043857              1628.131309  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_cases_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Calculate the number of people that are ACTUALLY infected on a given day\n",
    "currently infected = sum of people date - (recovored + died)\n",
    "ex: 5 = 10 - (4 - 1)\n",
    "\n",
    "'''\n",
    "current_infected = pd.DataFrame([])\n",
    "current_infected['currently_infected'] = (df.groupby('date').confirmed.sum() - \\\n",
    "                                          (df.groupby('date').deaths.sum() + df.groupby('date').recovered.sum()))\n",
    "current_infected['delta'] = (current_infected['currently_infected'] - df.groupby('date').confirmed.sum())\n",
    "daily_cases_df = pd.merge(daily_cases_df, current_infected, how='outer', on='date')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to data subdirectory...\n",
      "... ./data/2020-02-18\n",
      "Saving...\n",
      "... agg_data_2020-02-18.parquet.gzip\n",
      "... agg_data_2020-02-18.csv\n",
      "... trend_2020-02-18.csv\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Create date of extraction folder\n",
    "save_dir  = './data/' + str(datetime.date(datetime.now()))\n",
    "\n",
    "print('Saving to data subdirectory...')\n",
    "print('...', save_dir)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "print('Saving...')\n",
    "file_name = 'agg_data_{}.parquet.gzip'.format(datetime.date(datetime.now()))\n",
    "df.astype(str).to_parquet(os.path.join(save_dir, file_name), compression='gzip')\n",
    "print('...', file_name)\n",
    "\n",
    "\n",
    "csv_file_name = 'agg_data_{}.csv'.format(datetime.date(datetime.now()))\n",
    "df.astype(str).to_csv(os.path.join(save_dir, csv_file_name))\n",
    "print('...', csv_file_name)\n",
    "\n",
    "\n",
    "daily_cases_file_name = 'trend_{}.csv'.format(datetime.date(datetime.now()))\n",
    "daily_cases_df.astype(str).to_csv(os.path.join(save_dir, daily_cases_file_name))\n",
    "print('...', daily_cases_file_name)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python36864bitanaconda3virtualenv59e2ff4492e04649af7e0fd703909eac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
